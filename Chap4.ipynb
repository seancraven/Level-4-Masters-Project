{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import models \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core problem with nn is the competition between optimization and generalization. \n",
    "ie learn the general patterns of the problem, rather than specific patterns in the dataset. \n",
    "Dealing with overfitting, is refered to as regularisation.  \\\n",
    "- The smaller the network the less free parameters to fit and thus the most prominent patterns dominate.  \\  \n",
    "    - If there aren't enought free parameters then the fit will be impeded. This is where the'Art' of network design comes in \n",
    "- Weight regularisation L1,L2 Regularisation, network link cost*loss or network link cost*loss^2\n",
    "- Dropout, where you introduce noise into the output of layers by dropping nurons to make sure that significant patterns are addapted for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
